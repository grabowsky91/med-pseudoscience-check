"""
–û—Å–Ω–æ–≤–Ω–æ–π –º–æ–¥—É–ª—å –∞–Ω–∞–ª–∏–∑–∞ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö —Ç–µ–∫—Å—Ç–æ–≤ –Ω–∞ –ø—Å–µ–≤–¥–æ–Ω–∞—É—á–Ω—ã–µ —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è
"""

import re
from typing import Dict, List, Tuple, Optional
from datetime import datetime
import json

try:
    import spacy
    SPACY_AVAILABLE = True
except ImportError:
    SPACY_AVAILABLE = False
    print("–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: spaCy –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –ù–µ–∫–æ—Ç–æ—Ä—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –±—É–¥—É—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã.")

try:
    import nltk
    from nltk.tokenize import sent_tokenize, word_tokenize
    from nltk.corpus import stopwords
    NLTK_AVAILABLE = True
except ImportError:
    NLTK_AVAILABLE = False
    print("–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: NLTK –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –ù–µ–∫–æ—Ç–æ—Ä—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –±—É–¥—É—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã.")

from markets import (
    PSEUDOSCIENCE_MARKERS, RISK_CATEGORIES, LEGITIMATE_MEDICAL_TERMS,
    AMPLIFIERS, get_all_patterns, get_risk_level
)
from textloader import TextLoader, TextHighlighter


class PseudoscienceAnalyzer:
    """–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –ø—Å–µ–≤–¥–æ–Ω–∞—É—á–Ω—ã—Ö —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–π –≤ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö —Ç–µ–∫—Å—Ç–∞—Ö"""
    
    def __init__(self, language: str = 'russian', use_spacy: bool = True, 
                 use_nltk: bool = True):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
        
        Args:
            language: –Ø–∑—ã–∫ –∞–Ω–∞–ª–∏–∑–∞ ('russian' –∏–ª–∏ 'english')
            use_spacy: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å spaCy –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            use_nltk: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å NLTK –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        """
        self.language = language
        self.text_loader = TextLoader()
        self.highlighter = TextHighlighter(use_colors=True)
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π spaCy
        self.nlp = None
        if use_spacy and SPACY_AVAILABLE:
            try:
                model_name = 'ru_core_news_sm' if language == 'russian' else 'en_core_web_sm'
                self.nlp = spacy.load(model_name)
            except OSError:
                print(f"–ú–æ–¥–µ–ª—å {model_name} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ: python -m spacy download {model_name}")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ NLTK
        self.use_nltk = use_nltk and NLTK_AVAILABLE
        if self.use_nltk:
            try:
                # –ü–æ–ø—ã—Ç–∫–∞ –∑–∞–≥—Ä—É–∑–∏—Ç—å –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –¥–∞–Ω–Ω—ã–µ
                stopwords.words('russian' if language == 'russian' else 'english')
            except LookupError:
                print("–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö NLTK...")
                nltk.download('punkt', quiet=True)
                nltk.download('stopwords', quiet=True)
        
        # –ö–æ–º–ø–∏–ª—è—Ü–∏—è —Ä–µ–≥—É–ª—è—Ä–Ω—ã—Ö –≤—ã—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        self.compiled_patterns = self._compile_patterns()
    
    def _compile_patterns(self) -> Dict[str, List[re.Pattern]]:
        """
        –ö–æ–º–ø–∏–ª—è—Ü–∏—è –≤—Å–µ—Ö —Ä–µ–≥—É–ª—è—Ä–Ω—ã—Ö –≤—ã—Ä–∞–∂–µ–Ω–∏–π
        
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å–∫–æ–º–ø–∏–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
        """
        patterns = get_all_patterns(self.language)
        compiled = {}
        
        for category, pattern_list in patterns.items():
            compiled[category] = [
                re.compile(pattern, re.IGNORECASE | re.UNICODE)
                for pattern in pattern_list
            ]
        
        return compiled
    
    def analyze_text(self, text: str, detailed: bool = True) -> Dict:
        """
        –ü–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞
        
        Args:
            text: –¢–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            detailed: –í–∫–ª—é—á–∏—Ç—å –¥–µ—Ç–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
        
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∞–Ω–∞–ª–∏–∑–∞
        """
        # –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
        processed_text = self.text_loader.preprocess_text(text)
        detected_language = self.text_loader.detect_language(processed_text)
        
        # –ï—Å–ª–∏ —è–∑—ã–∫ —Ç–µ–∫—Å—Ç–∞ –æ—Ç–ª–∏—á–∞–µ—Ç—Å—è –æ—Ç –Ω–∞—Å—Ç—Ä–æ–µ–Ω–Ω–æ–≥–æ, –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–∞–µ–º
        language_warning = None
        if detected_language != self.language and detected_language != 'unknown':
            language_warning = (
                f"–í–Ω–∏–º–∞–Ω–∏–µ: –æ–±–Ω–∞—Ä—É–∂–µ–Ω —è–∑—ã–∫ '{detected_language}', "
                f"–Ω–æ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –Ω–∞—Å—Ç—Ä–æ–µ–Ω –Ω–∞ '{self.language}'"
            )
        
        # –ü–æ–∏—Å–∫ –ø—Å–µ–≤–¥–æ–Ω–∞—É—á–Ω—ã—Ö –º–∞—Ä–∫–µ—Ä–æ–≤
        markers_found = self._find_markers(processed_text)
        
        # –ü–æ–∏—Å–∫ –ª–µ–≥–∏—Ç–∏–º–Ω—ã—Ö –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤
        legitimate_terms = self._find_legitimate_terms(processed_text)
        
        # –ê–Ω–∞–ª–∏–∑ –∞–º–ø–ª–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–≤
        amplifiers_found = self._find_amplifiers(processed_text)
        
        # –ü–æ–¥—Å—á—ë—Ç –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
        category_counts = {}
        for marker in markers_found:
            category = marker['category']
            category_counts[category] = category_counts.get(category, 0) + 1
        
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É—Ä–æ–≤–Ω—è —Ä–∏—Å–∫–∞
        risk_level = get_risk_level(category_counts)
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ç–µ–∫—Å—Ç–∞
        text_stats = self.text_loader.get_text_stats(processed_text)
        
        # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        result = {
            'timestamp': datetime.now().isoformat(),
            'language_detected': detected_language,
            'language_warning': language_warning,
            'text_stats': text_stats,
            'risk_level': risk_level,
            'markers_count': len(markers_found),
            'category_counts': category_counts,
            'legitimate_terms_count': len(legitimate_terms),
            'amplifiers_count': len(amplifiers_found),
        }
        
        if detailed:
            result['markers'] = markers_found
            result['legitimate_terms'] = legitimate_terms
            result['amplifiers'] = amplifiers_found
            result['highlighted_text'] = self.highlighter.highlight_text(
                processed_text, markers_found
            )
        
        return result
    
    def _find_markers(self, text: str) -> List[Dict]:
        """
        –ü–æ–∏—Å–∫ –ø—Å–µ–≤–¥–æ–Ω–∞—É—á–Ω—ã—Ö –º–∞—Ä–∫–µ—Ä–æ–≤ –≤ —Ç–µ–∫—Å—Ç–µ
        
        Args:
            text: –¢–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        
        Returns:
            –°–ø–∏—Å–æ–∫ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –º–∞—Ä–∫–µ—Ä–æ–≤
        """
        markers = []
        
        for category, patterns in self.compiled_patterns.items():
            for pattern in patterns:
                for match in pattern.finditer(text):
                    marker = {
                        'category': category,
                        'text': match.group(0),
                        'start': match.start(),
                        'end': match.end(),
                        'severity': RISK_CATEGORIES[category]['severity'],
                        'description_ru': RISK_CATEGORIES[category]['description_ru'],
                        'description_en': RISK_CATEGORIES[category]['description_en'],
                    }
                    markers.append(marker)
        
        return markers
    
    def _find_legitimate_terms(self, text: str) -> List[Dict]:
        """
        –ü–æ–∏—Å–∫ –ª–µ–≥–∏—Ç–∏–º–Ω—ã—Ö –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤
        
        Args:
            text: –¢–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        
        Returns:
            –°–ø–∏—Å–æ–∫ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤
        """
        terms = []
        patterns = LEGITIMATE_MEDICAL_TERMS.get(self.language, [])
        
        for pattern_str in patterns:
            pattern = re.compile(pattern_str, re.IGNORECASE | re.UNICODE)
            for match in pattern.finditer(text):
                term = {
                    'text': match.group(0),
                    'start': match.start(),
                    'end': match.end(),
                }
                terms.append(term)
        
        return terms
    
    def _find_amplifiers(self, text: str) -> List[Dict]:
        """
        –ü–æ–∏—Å–∫ —Å–ª–æ–≤-–∞–º–ø–ª–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–≤
        
        Args:
            text: –¢–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        
        Returns:
            –°–ø–∏—Å–æ–∫ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –∞–º–ø–ª–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–≤
        """
        amplifiers = []
        words = AMPLIFIERS.get(self.language, [])
        
        for word in words:
            pattern = re.compile(r'\b' + re.escape(word) + r'\b', 
                               re.IGNORECASE | re.UNICODE)
            for match in pattern.finditer(text):
                amplifier = {
                    'text': match.group(0),
                    'start': match.start(),
                    'end': match.end(),
                }
                amplifiers.append(amplifier)
        
        return amplifiers
    
    def generate_report(self, analysis_result: Dict, format: str = 'text') -> str:
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á—ë—Ç–∞ –ø–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º –∞–Ω–∞–ª–∏–∑–∞
        
        Args:
            analysis_result: –†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞
            format: –§–æ—Ä–º–∞—Ç –æ—Ç—á—ë—Ç–∞ ('text', 'json', 'html')
        
        Returns:
            –û—Ç—á—ë—Ç –≤ –≤—ã–±—Ä–∞–Ω–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
        """
        if format == 'json':
            return json.dumps(analysis_result, ensure_ascii=False, indent=2)
        elif format == 'html':
            return self._generate_html_report(analysis_result)
        else:
            return self._generate_text_report(analysis_result)
    
    def _generate_text_report(self, result: Dict) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –æ—Ç—á—ë—Ç–∞"""
        lines = []
        lines.append("=" * 70)
        lines.append("–û–¢–ß–Å–¢ –ê–ù–ê–õ–ò–ó–ê –ú–ï–î–ò–¶–ò–ù–°–ö–û–ì–û –¢–ï–ö–°–¢–ê –ù–ê –ü–°–ï–í–î–û–ù–ê–£–ö–£")
        lines.append("=" * 70)
        lines.append("")
        
        # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        lines.append(f"–í—Ä–µ–º—è –∞–Ω–∞–ª–∏–∑–∞: {result['timestamp']}")
        lines.append(f"–û–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–π —è–∑—ã–∫: {result['language_detected']}")
        if result.get('language_warning'):
            lines.append(f"‚ö†Ô∏è  {result['language_warning']}")
        lines.append("")
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ç–µ–∫—Å—Ç–∞
        lines.append("–°–¢–ê–¢–ò–°–¢–ò–ö–ê –¢–ï–ö–°–¢–ê:")
        stats = result['text_stats']
        lines.append(f"  ‚Ä¢ –°–∏–º–≤–æ–ª–æ–≤: {stats['chars']}")
        lines.append(f"  ‚Ä¢ –°–ª–æ–≤: {stats['words']}")
        lines.append(f"  ‚Ä¢ –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π: {stats['sentences']}")
        lines.append(f"  ‚Ä¢ –°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è: {stats['avg_sentence_length']:.1f} —Å–ª–æ–≤")
        lines.append("")
        
        # –£—Ä–æ–≤–µ–Ω—å —Ä–∏—Å–∫–∞
        risk_level = result['risk_level']
        risk_icons = {
            'low': '‚úÖ',
            'medium': '‚ö†Ô∏è',
            'high': '‚ö†Ô∏è‚ö†Ô∏è',
            'critical': 'üö®'
        }
        risk_names = {
            'low': '–ù–ò–ó–ö–ò–ô',
            'medium': '–°–†–ï–î–ù–ò–ô',
            'high': '–í–´–°–û–ö–ò–ô',
            'critical': '–ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô'
        }
        
        lines.append(f"–£–†–û–í–ï–ù–¨ –†–ò–°–ö–ê: {risk_icons.get(risk_level, '?')} {risk_names.get(risk_level, risk_level.upper())}")
        lines.append("")
        
        # –ù–∞–π–¥–µ–Ω–Ω—ã–µ –º–∞—Ä–∫–µ—Ä—ã
        lines.append(f"–ù–ê–ô–î–ï–ù–û –ü–°–ï–í–î–û–ù–ê–£–ß–ù–´–• –ú–ê–†–ö–ï–†–û–í: {result['markers_count']}")
        
        if result['category_counts']:
            lines.append("")
            lines.append("–ü–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º:")
            for category, count in sorted(result['category_counts'].items(), 
                                        key=lambda x: x[1], reverse=True):
                cat_info = RISK_CATEGORIES.get(category, {})
                name = cat_info.get('name_ru', category)
                severity = cat_info.get('severity', 'unknown')
                lines.append(f"  ‚Ä¢ {name}: {count} (—Å–µ—Ä—å—ë–∑–Ω–æ—Å—Ç—å: {severity})")
        
        lines.append("")
        lines.append(f"–õ–µ–≥–∏—Ç–∏–º–Ω—ã—Ö –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤: {result['legitimate_terms_count']}")
        lines.append(f"–°–ª–æ–≤-–∞–º–ø–ª–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–≤: {result['amplifiers_count']}")
        lines.append("")
        
        # –î–µ—Ç–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
        if 'markers' in result and result['markers']:
            lines.append("=" * 70)
            lines.append("–î–ï–¢–ê–õ–¨–ù–ê–Ø –ò–ù–§–û–†–ú–ê–¶–ò–Ø –û –ù–ê–ô–î–ï–ù–ù–´–• –ú–ê–†–ö–ï–†–ê–•:")
            lines.append("=" * 70)
            lines.append("")
            
            for i, marker in enumerate(result['markers'], 1):
                cat_info = RISK_CATEGORIES.get(marker['category'], {})
                lines.append(f"{i}. ¬´{marker['text']}¬ª")
                lines.append(f"   –ö–∞—Ç–µ–≥–æ—Ä–∏—è: {cat_info.get('name_ru', marker['category'])}")
                lines.append(f"   –°–µ—Ä—å—ë–∑–Ω–æ—Å—Ç—å: {marker['severity']}")
                lines.append(f"   –û–ø–∏—Å–∞–Ω–∏–µ: {marker['description_ru']}")
                lines.append("")
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        lines.append("=" * 70)
        lines.append("–†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:")
        lines.append("=" * 70)
        lines.append("")
        
        if risk_level in ['high', 'critical']:
            lines.append("‚ö†Ô∏è  –í–ù–ò–ú–ê–ù–ò–ï! –¢–µ–∫—Å—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç –º–Ω–æ–∂–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø—Å–µ–≤–¥–æ–Ω–∞—É—á–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏.")
            lines.append("–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è:")
            lines.append("  ‚Ä¢ –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏")
            lines.append("  ‚Ä¢ –û–±—Ä–∞—Ç–∏—Ç—å—Å—è –∫ –∫–≤–∞–ª–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–º —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–∞–º")
            lines.append("  ‚Ä¢ –ò—Å–∫–∞—Ç—å –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è –≤ —Ä–µ—Ü–µ–Ω–∑–∏—Ä—É–µ–º—ã—Ö –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è—Ö")
        elif risk_level == 'medium':
            lines.append("‚ö†Ô∏è  –¢–µ–∫—Å—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –ø—Å–µ–≤–¥–æ–Ω–∞—É—á–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏.")
            lines.append("–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –ø—Ä–æ—è–≤–∏—Ç—å –∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–µ –º—ã—à–ª–µ–Ω–∏–µ –∏ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å —Ñ–∞–∫—Ç—ã.")
        else:
            lines.append("‚úÖ –¢–µ–∫—Å—Ç –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø—Å–µ–≤–¥–æ–Ω–∞—É–∫–∏.")
            lines.append("–û–¥–Ω–∞–∫–æ –≤—Å–µ–≥–¥–∞ –ø–æ–ª–µ–∑–Ω–æ –ø—Ä–æ–≤–µ—Ä—è—Ç—å –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏.")
        
        lines.append("")
        lines.append("=" * 70)
        
        return "\n".join(lines)
    
    def _generate_html_report(self, result: Dict) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è HTML –æ—Ç—á—ë—Ç–∞"""
        risk_colors = {
            'low': '#28a745',
            'medium': '#ffc107',
            'high': '#fd7e14',
            'critical': '#dc3545'
        }
        
        risk_color = risk_colors.get(result['risk_level'], '#6c757d')
        
        html = f"""
        <!DOCTYPE html>
        <html lang="ru">
        <head>
            <meta charset="UTF-8">
            <meta name="viewport" content="width=device-width, initial-scale=1.0">
            <title>–û—Ç—á—ë—Ç –∞–Ω–∞–ª–∏–∑–∞ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–≥–æ —Ç–µ–∫—Å—Ç–∞</title>
            <style>
                body {{
                    font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
                    line-height: 1.6;
                    max-width: 1200px;
                    margin: 0 auto;
                    padding: 20px;
                    background-color: #f5f5f5;
                }}
                .container {{
                    background: white;
                    padding: 30px;
                    border-radius: 10px;
                    box-shadow: 0 2px 10px rgba(0,0,0,0.1);
                }}
                h1 {{
                    color: #333;
                    border-bottom: 3px solid {risk_color};
                    padding-bottom: 10px;
                }}
                h2 {{
                    color: #555;
                    margin-top: 30px;
                }}
                .risk-level {{
                    font-size: 24px;
                    font-weight: bold;
                    color: {risk_color};
                    padding: 15px;
                    background: {risk_color}22;
                    border-left: 5px solid {risk_color};
                    border-radius: 5px;
                    margin: 20px 0;
                }}
                .stats {{
                    display: grid;
                    grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
                    gap: 15px;
                    margin: 20px 0;
                }}
                .stat-card {{
                    padding: 15px;
                    background: #f8f9fa;
                    border-radius: 5px;
                    border-left: 3px solid #007bff;
                }}
                .stat-value {{
                    font-size: 28px;
                    font-weight: bold;
                    color: #007bff;
                }}
                .stat-label {{
                    color: #666;
                    font-size: 14px;
                }}
                .category-list {{
                    list-style: none;
                    padding: 0;
                }}
                .category-item {{
                    padding: 10px;
                    margin: 5px 0;
                    background: #f8f9fa;
                    border-radius: 5px;
                }}
                .severity-high {{ border-left: 4px solid #dc3545; }}
                .severity-medium {{ border-left: 4px solid #ffc107; }}
                .severity-low {{ border-left: 4px solid #28a745; }}
                .marker {{
                    margin: 10px 0;
                    padding: 10px;
                    background: #fff3cd;
                    border-radius: 5px;
                }}
                .recommendations {{
                    background: #e7f3ff;
                    padding: 20px;
                    border-radius: 5px;
                    border-left: 5px solid #007bff;
                }}
            </style>
        </head>
        <body>
            <div class="container">
                <h1>üìä –û—Ç—á—ë—Ç –∞–Ω–∞–ª–∏–∑–∞ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–≥–æ —Ç–µ–∫—Å—Ç–∞</h1>
                
                <div class="risk-level">
                    –£—Ä–æ–≤–µ–Ω—å —Ä–∏—Å–∫–∞: {result['risk_level'].upper()}
                </div>
                
                <h2>üìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞</h2>
                <div class="stats">
                    <div class="stat-card">
                        <div class="stat-value">{result['markers_count']}</div>
                        <div class="stat-label">–ü—Å–µ–≤–¥–æ–Ω–∞—É—á–Ω—ã—Ö –º–∞—Ä–∫–µ—Ä–æ–≤</div>
                    </div>
                    <div class="stat-card">
                        <div class="stat-value">{result['text_stats']['words']}</div>
                        <div class="stat-label">–°–ª–æ–≤ –≤ —Ç–µ–∫—Å—Ç–µ</div>
                    </div>
                    <div class="stat-card">
                        <div class="stat-value">{result['legitimate_terms_count']}</div>
                        <div class="stat-label">–õ–µ–≥–∏—Ç–∏–º–Ω—ã—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤</div>
                    </div>
                    <div class="stat-card">
                        <div class="stat-value">{result['amplifiers_count']}</div>
                        <div class="stat-label">–°–ª–æ–≤-–∞–º–ø–ª–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–≤</div>
                    </div>
                </div>
                
                <h2>üìã –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –º–∞—Ä–∫–µ—Ä–æ–≤</h2>
                <ul class="category-list">
        """
        
        for category, count in sorted(result['category_counts'].items(), 
                                     key=lambda x: x[1], reverse=True):
            cat_info = RISK_CATEGORIES.get(category, {})
            name = cat_info.get('name_ru', category)
            severity = cat_info.get('severity', 'medium')
            html += f"""
                    <li class="category-item severity-{severity}">
                        <strong>{name}</strong>: {count}
                        <br><small>{cat_info.get('description_ru', '')}</small>
                    </li>
            """
        
        html += """
                </ul>
                
                <div class="recommendations">
                    <h2>üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏</h2>
        """
        
        if result['risk_level'] in ['high', 'critical']:
            html += """
                    <p>‚ö†Ô∏è <strong>–í–ù–ò–ú–ê–ù–ò–ï!</strong> –¢–µ–∫—Å—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç –º–Ω–æ–∂–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø—Å–µ–≤–¥–æ–Ω–∞—É—á–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏.</p>
                    <ul>
                        <li>–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏</li>
                        <li>–û–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ –∫–≤–∞–ª–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–º —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–∞–º</li>
                        <li>–ò—â–∏—Ç–µ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è –≤ —Ä–µ—Ü–µ–Ω–∑–∏—Ä—É–µ–º—ã—Ö –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è—Ö</li>
                    </ul>
            """
        elif result['risk_level'] == 'medium':
            html += """
                    <p>‚ö†Ô∏è –¢–µ–∫—Å—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –ø—Å–µ–≤–¥–æ–Ω–∞—É—á–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏.</p>
                    <p>–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –ø—Ä–æ—è–≤–∏—Ç—å –∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–µ –º—ã—à–ª–µ–Ω–∏–µ –∏ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å —Ñ–∞–∫—Ç—ã.</p>
            """
        else:
            html += """
                    <p>‚úÖ –¢–µ–∫—Å—Ç –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø—Å–µ–≤–¥–æ–Ω–∞—É–∫–∏.</p>
                    <p>–û–¥–Ω–∞–∫–æ –≤—Å–µ–≥–¥–∞ –ø–æ–ª–µ–∑–Ω–æ –ø—Ä–æ–≤–µ—Ä—è—Ç—å –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏.</p>
            """
        
        html += """
                </div>
                
                <p style="text-align: center; color: #999; margin-top: 40px;">
                    <small>–í—Ä–µ–º—è –∞–Ω–∞–ª–∏–∑–∞: {}</small>
                </p>
            </div>
        </body>
        </html>
        """.format(result['timestamp'])
        
        return html
    
    def export_report(self, analysis_result: Dict, filepath: str, 
                     format: str = 'text') -> None:
        """
        –≠–∫—Å–ø–æ—Ä—Ç –æ—Ç—á—ë—Ç–∞ –≤ —Ñ–∞–π–ª
        
        Args:
            analysis_result: –†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞
            filepath: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
            format: –§–æ—Ä–º–∞—Ç ('text', 'json', 'html')
        """
        report = self.generate_report(analysis_result, format)
        self.text_loader.save_to_file(report, filepath)